{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to convert, backup and log experiments\n",
    "\n",
    "* Requires MCDS commandline conversion tool\n",
    "* Requires GCE commandline tools and setup for account with access to storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "import logging\n",
    "import subprocess\n",
    "from google.cloud import storage\n",
    "\n",
    "gcs_client = storage.Client(project='divine-builder-142611')\n",
    "bucket = gcs_client.get_bucket('meadata')\n",
    "\n",
    "logpath = '/home/mestalbet/'\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# create a file handler\n",
    "handler = logging.FileHandler(os.path.join(logpath,'SpreadSheet_RunLog.log'))\n",
    "handler.setLevel(logging.INFO)\n",
    "\n",
    "# create a logging format\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# add the handlers to the logger\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk(d,suffix = '.msds'):\n",
    "    pys = []\n",
    "    for p, d, f in os.walk(d):\n",
    "        for file in f:\n",
    "            if file.endswith(suffix):\n",
    "                    pys.append(os.path.join(file))\n",
    "    return pys\n",
    "\n",
    "def scanforexperiments(searchpath,logpath):\n",
    "    '''\n",
    "    Takes a search path and looks recursively for all MSDS files\n",
    "    '''\n",
    "    logger.info('Start: Scan for new files')\n",
    "    files = walk(searchpath,'.msds')\n",
    "    logger.info('Process: %d _total_ files found' % len(files))\n",
    "    \n",
    "    # Checks if this was run in the past, if so, only processes the new files\n",
    "    oldfileslog = os.path.join(logpath,'filelist.p')\n",
    "    if os.path.isfile(oldfileslog):\n",
    "        pickle_in = open(oldfileslog,\"rb\")\n",
    "        oldfilelist = pickle.load(pickle_in)\n",
    "        pickle_in.close()\n",
    "        logger.info('Process: %d _old_ files found' % len(oldfileslist))\n",
    "    \n",
    "    pickle_out = open(oldfileslog,\"wb\")\n",
    "    pickle(files, pickle_out)\n",
    "    pickle_out.close()\n",
    "    logger.info('Process: Old files list updated')\n",
    "    \n",
    "    files  = list(set(files) & set(oldfileslist))\n",
    "    numfiles = len(files)\n",
    "    logger.info('Process: %d _new_ files found' % numfiles)\n",
    "    logger.info('End: Scan for files')\n",
    "    return(files,numfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsefields(files, splitchar = '<'):\n",
    "    text = [splitchar,'h5']\n",
    "    words = [f.split('/') for f in files]\n",
    "    keys =[]\n",
    "    values =[] \n",
    "    field = {}\n",
    "    for word in words:\n",
    "        key = 'exclude'\n",
    "        value = ''\n",
    "        field.setdefault(key, []).append(value)\n",
    "        field.setdefault(key, []).append(value)\n",
    "        key = 'folder'\n",
    "        value = '/'+os.path.join(*word[:-1])\n",
    "        field.setdefault(key, []).append(value)\n",
    "        field.setdefault(key, []).append(value)\n",
    "        key = 'coating'\n",
    "        value = 'PDL'\n",
    "        field.setdefault(key, []).append(value)\n",
    "        field.setdefault(key, []).append(value)\n",
    "        key = 'cleaning'\n",
    "        value = 'Liquinox, DDW'\n",
    "        field.setdefault(key, []).append(value)\n",
    "        field.setdefault(key, []).append(value)\n",
    "        for w in word:\n",
    "            if text[0] in w:\n",
    "                innerwords = w.split('_')\n",
    "                for innerword in innerwords:\n",
    "                    key =  innerword.split(splitchar)[0]\n",
    "                    value = innerword.split(splitchar)[1]\n",
    "                    field.setdefault(key, []).append(value)   \n",
    "                    field.setdefault(key, []).append(value)\n",
    "            elif text[1] in w:\n",
    "                key = 'MEAfiles'\n",
    "                value = w\n",
    "                field.setdefault(key, []).append(value) \n",
    "                field.setdefault(key, []).append(value.replace('h5','bin')) \n",
    "                key = 'recFormat'\n",
    "                value = \"MCH5Recording\"\n",
    "                field.setdefault(key, []).append(value)\n",
    "                field.setdefault(key, []).append(value.replace('MCH5','binary')) \n",
    "                key = 'recNames'\n",
    "                value = w\n",
    "                field.setdefault(key, []).append(value)\n",
    "                field.setdefault(key, []).append(value.replace('h5','bin')) \n",
    "        key = 'comments'\n",
    "        value = ''\n",
    "        field.setdefault(key, []).append(value) \n",
    "        return(field)\n",
    "\n",
    "def makeGSdir(bucket = bucket,directory = 'database/'):\n",
    "    blob = bucket.blob(directory)\n",
    "    blob.upload_from_string('', content_type='application/x-www-form-urlencoded;charset=UTF-8')\n",
    "    \n",
    "def createDirStructure(field):\n",
    "    table = pd.DataFrame(field)\n",
    "    t = table.groupby(['MEAfiles']).agg(['first'])\n",
    "    for r in t.rows:\n",
    "        directory = 'database'\n",
    "        for c in r.cols:\n",
    "            directory = os.path.join(directory,c+'=%s' % t.loc[c].value)\n",
    "            makeGSdir(directory)\n",
    "\n",
    "def converttoh5(files, fields, gspath, mcspath = '~/MCS_CommandLineTool/'):\n",
    "    '''\n",
    "    Takes files that were discovered and converts them to h5 then uploads them to google cloud\n",
    "    '''\n",
    "    logger.info('Start: Conversion from MSDS to H5')\n",
    "    for i in range(len(numfiles)):\n",
    "        bashCommand = \"%sMcsDataCommandLineConverter.exe -t hdf5 %s\" % (mcspath, files[i])\n",
    "        process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "        output, error = process.communicate()\n",
    "        if error is not None:\n",
    "            logger.error('File failed to convert with error: \\n %s' % error)\n",
    "                \n",
    "        logger.info('Process: Created directory structure on GS from file name %d / %d' % (i+1,numfiles))\n",
    "        filenames = [f.split('/')[-1].split('.')[0] for f in files]\n",
    "        fields = [f.split('_') for f in filenames]\n",
    "        logger.info('Process: Successfully converted file to H5')\n",
    "        logger.info('Process: Succesfully uploaded H5 to GS')\n",
    "\n",
    "    logger.info('End: Conversion from MSDS to H5')\n",
    "    return(h5files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writexls(path, d):\n",
    "    workbook = xlsxwriter.Workbook(path)\n",
    "    worksheet = workbook.add_worksheet()\n",
    "    col = 0 \n",
    "    for key in d.keys():\n",
    "        row = 0\n",
    "        worksheet.write(row, col, key)\n",
    "        for item in d[key]:\n",
    "            row += 1\n",
    "            worksheet.write(row, col, item)\n",
    "        col += 1\n",
    "    workbook.close()\n",
    "    return\n",
    "    \n",
    "def write_excel(gspath, field):\n",
    "    '''\n",
    "    Takes list of h5file paths and creates excel sheet. Saves to GS. \n",
    "    '''\n",
    "    logger.info('Start: Write Excel file log')\n",
    "\n",
    "    logger.info('Process: Successfully parsed directory structure')\n",
    "    logger.info('Process: Successfully updated Excel Sheet')\n",
    "    logger.info('Process: Succesfully copied log file and excel file to GS')\n",
    "\n",
    "\n",
    "    logger.info('End: Write Excel file log')\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
